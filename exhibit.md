1. [Champernown "Music from EDSAC" (circa 1960)](#d-g-champernown-music-from-edsac-circa-1960)
1. [Ben-Tal: "Notes for a future self"](#oded-ben-tal-notes-for-a-future-self)
1. [Robert Laidlow: "Alter" for mezzo-sporano and ensemble](#robert-laidlow-alter-for-mezzo-sporano-and-ensemble)
1. [Collaborative Electroacoustic Composition with Intelligent Agents](#collaborative-electroacoustic-composition-with-intelligent-agents-cecia)
1. [Kokoras: "AI Phantasy"](#panayiotis-kokoras-ai-phantasy)
1. [Coelho: "Music Transformer and DDSP Étude of Composition and Digital Performances"](#guilherme-coelho-music-transformer-and-ddsp-etude-of-composition-and-digital-performances)
1. [Lauren Hayes: "Moon via spirit" for live electronics](#lauren-hayes-moon-via-spirit-for-live-electronics)
1. [Lopez: "The Journey"](#alvaro-lopez-the-journey)
1. [Frisk: "pvm"](#henrik-frisk-pvm)

---

#### D. G. Champernown "Music from EDSAC" (circa 1960)

<a href="https://www.youtube.com/watch?v=gogIM2kKB1U&list=PLT_o2wa6T9d6ZMPnYW13XS6UoqymtxzN4
" target="_blank"><img src="http://img.youtube.com/vi/gogIM2kKB1U/0.jpg" 
alt="IMAGE ALT TEXT HERE" width="240" height="180" border="10" /></a>


https://highnoongmt.wordpress.com/2020/10/01/music-from-edsac-circa-1960/

---

#### Oded Ben-Tal: "Notes for a future self"

<a href="http://www.youtube.com/watch?feature=player_embedded&v=QmYt46Wl8JY
" target="_blank"><img src="http://img.youtube.com/vi/QmYt46Wl8JY/0.jpg" 
alt="IMAGE ALT TEXT HERE" width="240" height="180" border="10" /></a>

"Notes for a Future Self" was composed using deep learning tools, specifically folkrnn and Magenta. Both are deep learning models of symbolic music which I used in the composition process to generate material that I than transformed and adapted. Most of the material given to the percussionists came out of Magenta models. I experimented with both the melody generation and drum pattern generation modes and discovered that the most interesting results came out of confusing those: seeding the model with a melodic fragment but setting it to generate drum patterns. Or the other way round. The sequences generated in these ways were further transformed by mapping them onto groups of percussion instruments. The player is provided with guidelines about the composition of the set but is free to construct their own percussion set. Both the flute and the clarinet have extended solo moments in the piece, the melodic material of which was generated by folkrnn and further extended with Magenta. This material was again transformed in the composition away from the folk idiom of the origin. 

This is the third piece I composed using machine learning tools - following Bastard Tunes (2017) and Between the Lines (2018). In each piece the interaction between my own creative ideas and the machine learning system is different, but some general themes are emerging. The default output of the system is mostly useless. The initial phase involves significant amount of learning, on my part, of their supposed learning. Interesting results starts to appear when I learn how to subvert the model away from the training set. Starting the co-creative process with strong ideas about what I want to get out of the model is not going to work. If I know what I need I should either create it or program it.

---

#### Robert Laidlow: Alter for mezzo-sporano and ensemble

---

#### Collaborative Electroacoustic Composition with Intelligent Agents (CECIA)

---

#### Panayiotis Kokoras: AI Phantasy

---

#### Guilherme Coelho: Music Transformer and DDSP Étude of Composition and Digital Performances

---

#### Lauren Hayes: Moon via spirit for live electronics

---

#### Alvaro Lopez: The Journey

---

#### Henrik Frisk: pvm

